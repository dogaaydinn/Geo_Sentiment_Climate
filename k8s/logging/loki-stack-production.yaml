# Loki Stack for Production Log Aggregation
# Complete centralized logging solution with Loki, Promtail, and Grafana
#
# Components:
# - Loki: Log aggregation system
# - Promtail: Log collection agent
# - Grafana: Visualization and querying
#
# Features:
# - Horizontal scaling
# - S3/GCS backend storage
# - Log retention policies
# - Multi-tenancy support
# - Alert rules on logs
#
# Installation:
#   helm repo add grafana https://grafana.github.io/helm-charts
#   helm install loki grafana/loki-stack \
#     --namespace logging \
#     --create-namespace \
#     --values k8s/logging/loki-values.yaml

---
# ============================================================================
# Loki Configuration (loki-values.yaml for Helm)
# ============================================================================
#
# loki:
#   enabled: true
#
#   image:
#     repository: grafana/loki
#     tag: 2.9.3
#
#   persistence:
#     enabled: true
#     storageClassName: fast-ssd
#     size: 50Gi
#
#   config:
#     auth_enabled: false
#
#     ingester:
#       chunk_idle_period: 3m
#       chunk_block_size: 262144
#       chunk_retain_period: 1m
#       max_transfer_retries: 0
#       lifecycler:
#         ring:
#           kvstore:
#             store: inmemory
#           replication_factor: 1
#
#     limits_config:
#       enforce_metric_name: false
#       reject_old_samples: true
#       reject_old_samples_max_age: 168h  # 7 days
#       ingestion_rate_mb: 10
#       ingestion_burst_size_mb: 20
#
#     schema_config:
#       configs:
#         - from: 2020-10-24
#           store: boltdb-shipper
#           object_store: s3
#           schema: v11
#           index:
#             prefix: index_
#             period: 24h
#
#     server:
#       http_listen_port: 3100
#
#     storage_config:
#       boltdb_shipper:
#         active_index_directory: /data/loki/boltdb-shipper-active
#         cache_location: /data/loki/boltdb-shipper-cache
#         cache_ttl: 24h
#         shared_store: s3
#
#       aws:
#         s3: s3://us-east-1/geo-climate-loki-logs
#         s3forcepathstyle: false
#
#     chunk_store_config:
#       max_look_back_period: 0s
#
#     table_manager:
#       retention_deletes_enabled: true
#       retention_period: 2160h  # 90 days
#
#     compactor:
#       working_directory: /data/loki/boltdb-shipper-compactor
#       shared_store: s3

---
# Loki Deployment (if not using Helm)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki-headless
  replicas: 3
  selector:
    matchLabels:
      app: loki

  template:
    metadata:
      labels:
        app: loki
    spec:
      serviceAccountName: loki

      containers:
        - name: loki
          image: grafana/loki:2.9.3
          imagePullPolicy: IfNotPresent

          args:
            - -config.file=/etc/loki/loki.yaml

          ports:
            - name: http-metrics
              containerPort: 3100
              protocol: TCP
            - name: grpc
              containerPort: 9095
              protocol: TCP

          livenessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45

          readinessProbe:
            httpGet:
              path: /ready
              port: 3100
            initialDelaySeconds: 45

          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "4Gi"
              cpu: "2000m"

          volumeMounts:
            - name: config
              mountPath: /etc/loki
            - name: storage
              mountPath: /data

      volumes:
        - name: config
          configMap:
            name: loki-config

  volumeClaimTemplates:
    - metadata:
        name: storage
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 50Gi

---
# Loki Service
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
spec:
  type: ClusterIP
  ports:
    - name: http-metrics
      port: 3100
      targetPort: 3100
    - name: grpc
      port: 9095
      targetPort: 9095
  selector:
    app: loki

---
# Loki Headless Service
apiVersion: v1
kind: Service
metadata:
  name: loki-headless
  namespace: logging
spec:
  clusterIP: None
  ports:
    - name: http-metrics
      port: 3100
      targetPort: 3100
  selector:
    app: loki

---
# ============================================================================
# Promtail Configuration (Log Collector)
# ============================================================================

apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki:3100/loki/api/v1/push

    scrape_configs:
      # Kubernetes pod logs
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod

        pipeline_stages:
          # Extract log level
          - regex:
              expression: '.*level=(?P<level>\w+).*'
          - labels:
              level:

          # Parse JSON logs
          - json:
              expressions:
                timestamp: timestamp
                message: message
                level: level
                logger: logger

          # Add timestamp
          - timestamp:
              source: timestamp
              format: RFC3339Nano

        relabel_configs:
          # Add namespace label
          - source_labels:
              - __meta_kubernetes_pod_namespace
            target_label: namespace

          # Add pod name
          - source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod

          # Add container name
          - source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container

          # Add app label
          - source_labels:
              - __meta_kubernetes_pod_label_app
            target_label: app

          # Only scrape running pods
          - source_labels:
              - __meta_kubernetes_pod_phase
            regex: Running
            action: keep

          # Drop logs from kube-system (optional)
          # - source_labels:
          #     - __meta_kubernetes_pod_namespace
          #   regex: kube-system
          #   action: drop

      # System logs
      - job_name: system
        static_configs:
          - targets:
              - localhost
            labels:
              job: varlogs
              __path__: /var/log/*log

---
# Promtail DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
spec:
  selector:
    matchLabels:
      app: promtail

  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail

      containers:
        - name: promtail
          image: grafana/promtail:2.9.3
          imagePullPolicy: IfNotPresent

          args:
            - -config.file=/etc/promtail/promtail.yaml

          ports:
            - name: http-metrics
              containerPort: 9080
              protocol: TCP

          env:
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName

          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "200m"

          volumeMounts:
            - name: config
              mountPath: /etc/promtail
            - name: run
              mountPath: /run/promtail
            - name: varlog
              mountPath: /var/log
              readOnly: true
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true

          securityContext:
            runAsUser: 0
            runAsGroup: 0

      volumes:
        - name: config
          configMap:
            name: promtail-config
        - name: run
          hostPath:
            path: /run/promtail
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers

      tolerations:
        - effect: NoSchedule
          operator: Exists

---
# ============================================================================
# RBAC for Loki and Promtail
# ============================================================================

apiVersion: v1
kind: ServiceAccount
metadata:
  name: loki
  namespace: logging

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: logging

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "watch", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
subjects:
  - kind: ServiceAccount
    name: promtail
    namespace: logging
roleRef:
  kind: ClusterRole
  name: promtail
  apiGroup: rbac.authorization.k8s.io

---
# ============================================================================
# Grafana Integration
# ============================================================================

# Grafana Datasource for Loki
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  loki-datasource.yaml: |
    apiVersion: 1
    datasources:
      - name: Loki
        type: loki
        access: proxy
        url: http://loki.logging.svc.cluster.local:3100
        jsonData:
          maxLines: 1000
          derivedFields:
            - datasourceUid: prometheus
              matcherRegex: "traceID=(\\w+)"
              name: TraceID
              url: "$${__value.raw}"

---
# ============================================================================
# Log-based Alerts
# ============================================================================

# LogQL Alert Rules
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: loki-alerts
  namespace: logging
spec:
  groups:
    - name: loki_alerts
      interval: 30s
      rules:
        - alert: HighErrorRate
          expr: |
            sum(rate({namespace="geo-climate",level="error"}[5m])) by (app) > 10
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High error rate in {{ $labels.app }}"
            description: "Application {{ $labels.app }} is producing more than 10 errors per second."

        - alert: DatabaseConnectionErrors
          expr: |
            count_over_time({namespace="geo-climate",app="geo-climate-api"} |~ "database connection.*failed"[5m]) > 5
          for: 2m
          labels:
            severity: critical
          annotations:
            summary: "Database connection errors detected"
            description: "Multiple database connection failures detected in the last 5 minutes."

        - alert: OOMKilled
          expr: |
            count_over_time({namespace="geo-climate"} |~ "OOMKilled"[10m]) > 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Pod killed due to OOM"
            description: "A pod was killed due to out of memory."

---
# ============================================================================
# Log Retention and Cleanup
# ============================================================================

# Table Manager for retention (part of Loki config)
# Configured in loki.yaml:
#
# table_manager:
#   retention_deletes_enabled: true
#   retention_period: 2160h  # 90 days

---
# ============================================================================
# USAGE EXAMPLES
# ============================================================================
#
# LogQL Query Examples:
# --------------------
#
# 1. View all logs from geo-climate namespace:
#    {namespace="geo-climate"}
#
# 2. Filter by log level:
#    {namespace="geo-climate",level="error"}
#
# 3. Search for specific text:
#    {namespace="geo-climate"} |= "database connection failed"
#
# 4. Regular expression search:
#    {namespace="geo-climate"} |~ "error.*timeout"
#
# 5. Parse JSON and filter:
#    {namespace="geo-climate"} | json | status_code >= 500
#
# 6. Count error rate:
#    sum(rate({namespace="geo-climate",level="error"}[5m])) by (app)
#
# 7. Top 10 error messages:
#    topk(10, sum by (msg) (count_over_time({namespace="geo-climate",level="error"}[1h])))
#
# 8. Trace correlation:
#    {namespace="geo-climate"} | json | trace_id="abc123"
#
# 9. Slow query detection:
#    {namespace="geo-climate",app="geo-climate-api"} | json | duration > 1000
#
# 10. Failed authentication attempts:
#     {namespace="geo-climate"} |~ "authentication failed" | json | user_id != ""
#
#
# CLI Usage (logcli):
# ------------------
#
# Install:
#   brew install logcli  # macOS
#   go install github.com/grafana/loki/cmd/logcli@latest
#
# Port-forward Loki:
#   kubectl port-forward -n logging svc/loki 3100:3100
#
# Query logs:
#   export LOKI_ADDR=http://localhost:3100
#   logcli query '{namespace="geo-climate"}'
#
# Tail logs:
#   logcli query --tail '{namespace="geo-climate",app="geo-climate-api"}'
#
# Filter by time:
#   logcli query --since=1h '{namespace="geo-climate",level="error"}'
#
# Export logs:
#   logcli query --since=24h '{namespace="geo-climate"}' > logs.txt
#
#
# Grafana Explore:
# ---------------
# 1. Open Grafana: https://grafana.geo-climate.example.com
# 2. Navigate to Explore
# 3. Select "Loki" datasource
# 4. Enter LogQL query
# 5. Use log context feature to see surrounding logs
#
#
# Performance Tuning:
# ------------------
#
# 1. Increase ingestion rate:
#    limits_config:
#      ingestion_rate_mb: 20
#      ingestion_burst_size_mb: 40
#
# 2. Optimize query performance:
#    - Use label filters before text filters
#    - Limit time range
#    - Use metrics queries (count_over_time) instead of log queries
#
# 3. Storage optimization:
#    - Use S3/GCS for long-term storage
#    - Enable compression
#    - Adjust chunk sizes
#
# 4. Resource allocation:
#    - Scale Loki horizontally for high volume
#    - Use dedicated nodes for Loki
#    - Monitor memory usage
#
#
# Troubleshooting:
# ---------------
#
# 1. Promtail not collecting logs:
#    kubectl logs -n logging daemonset/promtail
#    # Check /tmp/positions.yaml for progress
#
# 2. Loki high memory usage:
#    # Reduce retention period or increase resources
#    # Check for expensive queries
#
# 3. Missing logs:
#    # Verify Promtail is running on all nodes
#    kubectl get pods -n logging -l app=promtail
#
#    # Check Loki ingester health
#    curl http://loki:3100/ready
#
# 4. Slow queries:
#    # Add more specific label filters
#    # Reduce time range
#    # Check Loki metrics for bottlenecks
#
# ============================================================================
# COST OPTIMIZATION
# ============================================================================
#
# Storage Costs (S3 backend):
# --------------------------
# Assuming 10GB/day log volume, 90-day retention:
#
# - Storage: 900GB * $0.023/GB = $20.70/month
# - PUT requests: ~10M/month * $0.005/1000 = $50/month
# - GET requests: ~1M/month * $0.0004/1000 = $0.40/month
#
# Total: ~$71/month
#
# Optimization strategies:
# -----------------------
# 1. Use S3 Intelligent-Tiering
# 2. Compress logs (gzip)
# 3. Filter unnecessary logs at Promtail level
# 4. Reduce retention for verbose logs
# 5. Use cheaper storage class for old logs
#
# ============================================================================
