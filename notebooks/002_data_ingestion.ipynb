{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:15.859066Z",
     "start_time": "2025-01-10T15:46:15.855652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [markdown]\n",
    "# # Data Ingestion Analysis\n",
    "#\n",
    "# Bu notebook, `data_ingestion` modülünü kullanarak ham veri setlerini işler ve sonuçları analiz eder."
   ],
   "id": "ac8eed971e1ded0e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:17.014355Z",
     "start_time": "2025-01-10T15:46:17.011801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ],
   "id": "582ffa3d10844a11",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:17.838622Z",
     "start_time": "2025-01-10T15:46:17.835729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "sys.path.append(os.path.abspath(\"../source\"))"
   ],
   "id": "d93734e4bf13595a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:19.192966Z",
     "start_time": "2025-01-10T15:46:19.176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "# Import necessary functions\n",
    "from source.data_ingestion import ingest_data\n",
    "from source.utils.config_loader import load_config\n",
    "from source.utils.logger import setup_logger"
   ],
   "id": "e50eecf18958f6ee",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:20.741640Z",
     "start_time": "2025-01-10T15:46:20.738886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "# %% [markdown]\n",
    "# ## Load Configuration"
   ],
   "id": "24e7efede8175a9c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:29.303841Z",
     "start_time": "2025-01-10T15:46:29.296765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "config_path = Path(\"../config/settings.yml\").resolve()\n",
    "config = load_config(config_path)\n",
    "\n",
    "if config is None:\n",
    "    logging.error(\"Failed to load configuration. Terminating notebook.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "RAW_DIR = Path(config[\"paths\"][\"raw_dir\"]).resolve()\n",
    "LOG_DIR = Path(config[\"paths\"].get(\"logs_dir\", \"../04-logs\")).resolve()\n",
    "\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger = setup_logger(\n",
    "    name=\"data_ingestion_notebook\",\n",
    "    log_file=LOG_DIR / \"data_ingestion_notebook.log\",\n",
    "    log_level=config.get(\"logging\", {}).get(\"level\", \"INFO\").upper()\n",
    ")\n",
    "\n",
    "logger.info(\"=== Data Ingestion Notebook Initialized ===\")"
   ],
   "id": "df2f29d4a2b330fc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-10 18:46:29,302 - data_ingestion_notebook - INFO - === Data Ingestion Notebook Initialized ===\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:46:31.678199Z",
     "start_time": "2025-01-10T15:46:31.676012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %%\n",
    "# %% [markdown]\n",
    "# ## Perform Data Ingestion"
   ],
   "id": "565592e20976e202",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T15:53:24.373517Z",
     "start_time": "2025-01-10T15:53:24.340276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "ingest_data(raw_dir=RAW_DIR)"
   ],
   "id": "b9672cde6a38da80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-10 18:53:24,340 - data_ingestion - INFO - === Starting data ingestion process ===\u001B[0m\n",
      "\u001B[32m2025-01-10 18:53:24,343 - data_ingestion - INFO - Found 515 CSV files in /Users/dogaaydin/PycharmProjects/Geo_Sentiment_Climate/data/raw\u001B[0m\n",
      "\u001B[32m2025-01-10 18:53:24,344 - data_ingestion - INFO - Processing file: epa_so2_virginia_2023.csv\u001B[0m\n",
      "\u001B[32m2025-01-10 18:53:24,352 - data_ingestion - INFO - Deduplicated epa_so2_virginia_2023.csv: (2877, 21) -> (2877, 21)\u001B[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# %%\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m ingest_data(raw_dir\u001B[38;5;241m=\u001B[39mRAW_DIR)\n",
      "File \u001B[0;32m~/PycharmProjects/Geo_Sentiment_Climate/source/data_ingestion.py:236\u001B[0m, in \u001B[0;36mingest_data\u001B[0;34m(raw_dir)\u001B[0m\n\u001B[1;32m    233\u001B[0m combined_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m csv_path \u001B[38;5;129;01min\u001B[39;00m csv_files:\n\u001B[0;32m--> 236\u001B[0m     processed_df \u001B[38;5;241m=\u001B[39m process_file(\n\u001B[1;32m    237\u001B[0m         csv_path\u001B[38;5;241m=\u001B[39mcsv_path,\n\u001B[1;32m    238\u001B[0m         required_columns\u001B[38;5;241m=\u001B[39mrequired_columns,\n\u001B[1;32m    239\u001B[0m         metadata\u001B[38;5;241m=\u001B[39mmetadata,\n\u001B[1;32m    240\u001B[0m         max_rows_read\u001B[38;5;241m=\u001B[39mMAX_ROWS_READ\n\u001B[1;32m    241\u001B[0m     )\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m processed_df\u001B[38;5;241m.\u001B[39mempty:\n\u001B[1;32m    244\u001B[0m         combined_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([combined_df, processed_df], ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/Geo_Sentiment_Climate/source/data_ingestion.py:182\u001B[0m, in \u001B[0;36mprocess_file\u001B[0;34m(csv_path, required_columns, metadata, max_rows_read)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# Update metadata\u001B[39;00m\n\u001B[1;32m    181\u001B[0m rows_count \u001B[38;5;241m=\u001B[39m final_shape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 182\u001B[0m mark_file_as_processed(file_name, file_hash, rows_count, metadata, METADATA_PATH)\n\u001B[1;32m    183\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m marked as processed with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrows_count\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[0;32m~/PycharmProjects/Geo_Sentiment_Climate/source/utils/metadata_manager.py:36\u001B[0m, in \u001B[0;36mmark_file_as_processed\u001B[0;34m(file_name, file_hash, rows_count, metadata, metadata_path)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmark_file_as_processed\u001B[39m(file_name: \u001B[38;5;28mstr\u001B[39m, file_hash: \u001B[38;5;28mstr\u001B[39m, rows_count: \u001B[38;5;28mint\u001B[39m, metadata: Dict, metadata_path: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     30\u001B[0m     metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocessed_files\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: file_name,\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m: file_hash,\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocessed_at\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39misoformat(),\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrows_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: rows_count\n\u001B[1;32m     35\u001B[0m     })\n\u001B[0;32m---> 36\u001B[0m     save_processed_files(metadata, metadata_path)\n",
      "File \u001B[0;32m~/PycharmProjects/Geo_Sentiment_Climate/source/utils/metadata_manager.py:19\u001B[0m, in \u001B[0;36msave_processed_files\u001B[0;34m(data, metadata_path)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msave_processed_files\u001B[39m(data: Dict, metadata_path: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     18\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(metadata_path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 19\u001B[0m     temp_path \u001B[38;5;241m=\u001B[39m metadata_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.tmp\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(temp_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     21\u001B[0m         json\u001B[38;5;241m.\u001B[39mdump(data, f, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# %%\n",
    "# %% [markdown]\n",
    "# ## Load and Display Combined Data"
   ],
   "id": "c0ad596934f583d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "processed_dir = Path(config[\"paths\"][\"processed_dir\"]).resolve()\n",
    "combined_file = processed_dir / \"epa_long_preprocessed.csv\"\n",
    "\n",
    "if combined_file.exists():\n",
    "    logger.info(f\"Loading combined data from {combined_file}\")\n",
    "    df_combined = pd.read_csv(combined_file)\n",
    "    display(df_combined.head())\n",
    "else:\n",
    "    logger.warning(f\"Combined data file {combined_file} does not exist.\")"
   ],
   "id": "a338570ef3d8ef71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "# %% [markdown]\n",
    "# ## Summary Statistics"
   ],
   "id": "e29202a9754713ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "if 'df_combined' in locals() and not df_combined.empty:\n",
    "    summary = df_combined.describe(include='all').transpose()\n",
    "    display(summary)\n",
    "else:\n",
    "    logger.warning(\"No combined data available for summary statistics.\")"
   ],
   "id": "2997aeab9d805949"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "# %% [markdown]\n",
    "# ## Visualization"
   ],
   "id": "16f49229428d4104"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure plots are rendered inline\n",
    "%matplotlib inline"
   ],
   "id": "3ede5b3efb5687f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if 'df_combined' in locals() and not df_combined.empty:\n",
    "    # Histogram of row counts per file can be inferred from metadata\n",
    "    metadata_path = Path(config[\"paths\"][\"metadata_dir\"]) / \"processed_files.json\"\n",
    "    try:\n",
    "        metadata = pd.read_json(metadata_path)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(metadata['rows_count'], bins=30, kde=True)\n",
    "        plt.title(\"Distribution of Row Counts per File\")\n",
    "        plt.xlabel(\"Row Count\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load metadata for visualization: {e}\")"
   ],
   "id": "3c3ca067ddb5d435"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Boxplot of missing values in required columns\n",
    "    required_columns = config[\"data_check\"].get(\"required_columns\", [])\n",
    "    if required_columns:\n",
    "        missing_counts = df_combined[required_columns].isnull().sum()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x=missing_counts.index, y=missing_counts.values)\n",
    "        plt.title(\"Missing Values in Required Columns\")\n",
    "        plt.xlabel(\"Columns\")\n",
    "        plt.ylabel(\"Number of Missing Values\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "else:\n",
    "    logger.warning(\"No combined data available for visualization.\")"
   ],
   "id": "1a91ae76fa0f8740"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoenv",
   "language": "python",
   "name": "geoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
